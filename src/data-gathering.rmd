---
title: "Gathering FP Data for Analysis"
output: 
  html_document:
    self_contained: no
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = FALSE,
  eval = FALSE
)
```

## Sources

The raw data can be found on these websites:

- [Horizon Dashboard](https://webgate.ec.europa.eu/dashboard)
  - `Everyone` ➜ `FP7 Projects` ➜ `FP7 Project Details` ➜ `Top Funded Projects`  
  - `Everyone` ➜ `H2020 Projects` ➜ `H2020 Projects` ➜ `Top Funded Projects`  
  - `Everyone` ➜ `H2020 Projects` ➜ `Data Export` ➜ `Raw Data Export Sheet`
- [EU Data Portal](https://data.europa.eu)
  - [FP7 projects](https://data.europa.eu/data/datasets/cordisfp7projects)  
  - [H2020 projects](https://data.europa.eu/data/datasets/cordish2020projects)
  - [CORDIS Reference Data](https://data.europa.eu/data/datasets/cordisref-data)

## Getting the data

### Horizon Dashboard

The [Horizon Dashboard](https://webgate.ec.europa.eu/dashboard) consists of a Qlik Sense application. Raw data are used in the official statistics of the European Commission but cannot be downloaded automatically. However, certain datasets can still be manually exported to `xlsx` files (see [Sources](#sources) above).

### Data Portal

The EU produces snapshots of its publicly available data on the [EU Data Portal](https://data.europa.eu). Data can be found for FP6, FP7, and H2020. For FP7 and H2020, the most recent data are stored in ZIP archives containing CSV files about projects and participants.

It is possible to download the data by hand or automatically. The following outlines how to download the data automatically with the command-line and the [Wget](https://www.gnu.org/software/wget) command.

First, we create a text file, `inst/url_list.txt`, with the list of URLs from which we would like to download the data files.

```{r urls, comment='', eval=TRUE, echo=FALSE}
cat(readLines(here::here("inst", "url_list.txt")), sep = '\n')
```

Second, we create a shell script, `inst/download_files.sh`, which downloads the data files to the `data-raw/` folder.

```{bash}
#!/bin/bash
while read url; do
	wget -P ../data-raw $url
done < ../inst/url_list.txt
```

Besides, it is also possible to inspect when the files were last updated. We do this by creating another shell script, `inst/last_updated.sh`, which displays the `Last-Modidied` information for each file.

```{bash}
#!/bin/bash
while read url; do
	wget --server-response --spider $url 2>&1 | grep -i Last-Modified
done < ../inst/urls.txt
```

To finish, we extract the files from the ZIP archives. The [unzip](http://infozip.sourceforge.net) command fails to extract the files from the Zip archives.  The most recent release contains a faulty Zip file structure. Fortunately, the [tar](https://www.gnu.org/software/tar) command offers a workaround.

```{bash}
#!/bin/bash
tar -xvf data-raw/cordis-fp7projects-csv.zip
mkdir data-raw/fp7
mv csv data-raw/fp7
tar -xvf data-raw/cordis-h2020projects-csv.zip
mkdir data-raw/h2020
mv csv data-raw/h2020
```

## Data Preprocessing

The first step is to load a few useful [libraries](https://github.com/zambujo/swissparticipation/blob/main/R/package.r) and helper [functions](https://github.com/zambujo/swissparticipation/blob/main/R/utils.R).

```{r}
source(here::here("R", "package.r"))
source(here::here("R", "utils.r"))
```

### Project Details

#### Horizon Dashboard

The data from the Horizon Dashboard only cover FP7 and H2020. The details about the projects are given in two tables, one per Framework Programme. Therefore, we select the matching columns to make it possible to merge the two tables.

```{r load-projects-dashboard-data}
matching_columns <- c(
  "project_id",
  "project_acronym",
  "thematic_priority",
  "topic_code",
  "topic_description",
  "participations"
)

fp7_dashboard <-
  # import xlsx to data frame
  here("data-raw", "fp7-projects.xlsx") %>%
  read_excel(guess_max = 20000) %>%
  # convert names to snake case
  clean_names() %>%
  # rename columns for consistency between tables
  rename(
    project_id = project_nbr,
    thematic_priority = thematic_priority_descr) %>%
  select(all_of(matching_columns)) %>%
  # data frame label column
  mutate(framework_programme = "FP7")

h2020_dashboard <-
  # import xlsx to data frame
  here("data-raw", "h2020-projects.xlsx") %>%
  read_excel(guess_max = 20000) %>%
  # convert names to snake case
  clean_names() %>%
  # rename columns for consistency between tables
  rename(
    project_id = project_nbr,
    thematic_priority = thema,
    participations = h2020_participations
  ) %>%
  select(all_of(matching_columns)) %>%
  # data frame label column
  mutate(framework_programme = "H2020")

# merge the tables
projects_dashboard <- bind_rows(fp7_dashboard, h2020_dashboard)
```

#### Data Portal

Details about the projects can also be found in the data downloaded from the Data Portal. Similarly to the Horizon Dashboard data, each Framework Programme has its own data table from which we select a few additional columns of interest.

```{r load-projects-cordis-data}
additional_columns <- c(
  "project_id",
  "start_date",
  "end_date",
  "legal_basis",
  "funding_scheme"
)

# use H2020 schema as reference
projects_cordis_h2020 <-
  read_csv2(here("data-raw", "h2020", "csv", "project.csv")) %>%
  # for data type consistency
  mutate_if(is.POSIXct, as.Date)

  mutate(contentUpdateDate = as.Date(contentUpdateDate))

projects_cordis_fp7 <-
  readr::read_csv2(here("data-raw", "fp7", "csv", "project.csv")) %>%
  # for data type consistency
  mutate(
    contentUpdateDate = as.Date(contentUpdateDate),
    ecSignatureDate = as.Date(ecSignatureDate),
    masterCall = as.character(masterCall))

projects_cordis <- bind_rows(projects_cordis_fp7, projects_cordis_h2020) %>%
  # use snake case
  clean_names() %>%
  # rename columns for consistency between tables
  rename(project_id = id) %>%
  select(all_of(additional_columns))
```

Finally, we combine the details from the Horizon Dashboard and the Data Portal.

```{r load-projects-data}
projects <- full_join(projects_dashboard, projects_cordis, by = "project_id")
```

##### FP6

For completeness, we also include the R-code which reads the data available for FP6. As indicated already, the Horizon Dashboard contains no data for FP6. Moreover, the Data Portal only provides contribution amounts for 2,621 cases (out of 75,241). The data from FP6 will therefore be ignored in the remainder of this work. 

```{r fp6, eval=FALSE}
# FP6 project details
projects_cordis_fp6 <-
  here("data-raw", "cordis-fp6projects.csv") %>%
  readr::read_csv2() %>%
  clean_names()

# FP6 participation/contribution details
organizations_cordis_fp6 <-
  here("data-raw", "cordis-fp6organizations.csv") %>%
  read_tsv() # beware: tsv, not csv
```

### Participation Details

#### Horizon Dashboard

Horizon Dashboard only includes participation data for H2020 and not for FP7. Nevertheless, the data in the Horizon Dashboard appear to be of a higher quality than that of the Data Portal and are therefore used as a source of official statistics.

First, we save the data to CSV, for [future reference](https://flatgithub.com/zambujo/swissparticipation).

```{r}
organizations_dashboard_h2020 <-
  here("data-raw", "horizon2020.xlsx") %>%
  read_excel() %>%
  clean_names() %>%
  rename(project_id = project_nbr,
         pic = general_pic)

# add call year
organizations_dashboard_h2020 <- organizations_dashboard_h2020 %>%
  mutate(
    call_date = as.Date(call_deadline_date, "%d/%m/%Y"),
    call_year = format(call_date, "%Y")
  ) %>%
  select(-call_date)

# store data types
map_chr(organizations_dashboard_h2020, class) %>%
  write_yaml(here("data", "schema-dashboard_export.yml"))

# split data frame by call year
yrs <- organizations_dashboard_h2020 %>%
  distinct(call_year) %>%
  pull() %>% sort()

file_names <- here("data", glue("dashboard-export-{yrs}.csv"))

organizations_dashboard_h2020 %>%
  arrange(call_year) %>%
  group_by(call_year) %>%
  group_split() %>%
  setNames(yrs) %>%
  # write to ./data
  walk2(file_names, vroom_write, delim = ",")
```

And select a few columns of interest.

```{r}
additional_columns <- c(
  "project_id",
  "pic",
  "partner_role",
  "pillar_abbr",
  "pillar_descr",
  "thematic_priority_abbr",
  "signature_date",
  "call_deadline_date",
  "eu_contribution")

organizations_dashboard_h2020 <- organizations_dashboard_h2020 %>%
  select(all_of(additional_columns))
```

#### Data Portal

Participation details are provided in the *organization.csv* tables.

```{r, load-organizations-cordis-data}
organizations_cordis_h2020 <-
  here("data-raw", "h2020", "csv", "organization.csv") %>%
  read_csv2(guess_max = 100000) %>%
  select(
    -contentUpdateDate,
    -SME,
    -nutsCode,
    -endOfParticipation,
    -active,
    -totalCost,
    -rcn
  )

organizations_cordis_fp7 <-
  here("data-raw", "fp7", "csv", "organization.csv") %>%
  read_csv2(guess_max = 130000) %>%
  select(
    -contentUpdateDate,
    -SME,
    -nutsCode,
    -endOfParticipation,
    -active,
    -totalCost,
    -rcn
  )

# Attention!
# 3 cases where (project_id, pic)
# appear 2x w/ different partner_role

organizations_cordis <-
  organizations_cordis_fp7 %>%
  bind_rows(organizations_cordis_h2020) %>%
  clean_names() %>%
  select(
    project_id,
    pic = organisation_id,
    legal_name = name,
    legal_short_name = short_name,
    legal_entity_type = activity_type,
    country_code = country,
    legal_url = organization_url,
    partner_role = role,
    ec_contribution,
    net_ec_contribution
  )
```


Once again, we combine both datasets:

```{r, load-organizations-data}
organizations <-
  organizations_dashboard_h2020 %>%
  full_join(organizations_cordis,
    by = c("project_id", "pic", "partner_role")
  )
```

### Project and Participation Details Combined

Having combined both CORDIS and Horizon Dashboard datasets, we obtain three columns with contribution details: `ec_contribution` (CORDIS), `net_ec_contribution` (CORDIS), and `eu_contribution` (Horizon Dashboard). As the European Commission official reporting is based on `eu_contribution` from the Horizon Dashboard, we will check how the values from CORDIS -- `ec_contribution` and `net_ec_contribution` -- compare to `eu_contribution` under H2020.

```{r viz-contributions, eval=FALSE}
dfsample <- organizations %>%
  filter(!is.na(net_ec_contribution)) %>%
  sample_n(10000)
plot(
  dfsample$ec_contribution,
  dfsample$eu_contribution,
  type = "p",
  pch = 19,
  cex = .5,
  log = "xy"
)
plot(
  dfsample$net_ec_contribution,
  dfsample$eu_contribution,
  type = "p",
  pch = 19,
  cex = .5,
  log = "xy"
)
```


```{r}
# check differences
anti_join(organizations, projects, by = "project_id")
anti_join(projects, organizations, by = "project_id")

df_raw <- organizations %>%
  left_join(projects, by = "project_id")
```

Below, we add country names and perform minor cleaning of the data set.

```{r transform}
# download CORDIS country codes
country_codes <-
  "https://cordis.europa.eu/data/reference/cordisref-countries.csv" %>%
  read_csv2() %>%
  clean_names() %>%
  filter(language == "en") %>%
  distinct(eu_code, name) %>%
  rename(country_code = eu_code, country = name)

df_raw <- df_raw %>%
  mutate(
    legal_entity_type = str_sub(legal_entity_type, 1, 3),
    country_code = str_sub(country_code, 1, 2),
    # rename role
    partner_role = str_to_title(partner_role),
    pillar = str_extract(pillar_abbr, "\\d"),
    pillar = if_else(pillar_abbr == "EU.0.", "Cross-theme", pillar),
    pillar = if_else(pillar_abbr == "Euratom", pillar_abbr, pillar),
    # clean contributions
    ec_contribution = str_replace(ec_contribution, ",", "."),
    ec_contribution = str_replace(
      ec_contribution,
      fixed("xxxxx"),
      NA_character_
    ),
    eu_contribution = str_replace(eu_contribution, fixed("-"), "0"),
    ec_contribution = as.numeric(ec_contribution),
    net_ec_contribution = as.numeric(net_ec_contribution),
    eu_contribution = as.numeric(eu_contribution),
    # reconcile FP7 and H2020 contribution data
    re_contribution = eu_contribution,
    re_contribution = if_else(is.na(re_contribution),
      net_ec_contribution,
      re_contribution
    ),
    re_contribution = if_else(is.na(re_contribution),
      ec_contribution,
      re_contribution
    ),
    # country code
    country_code = str_replace(country_code, "KO", "XK"),
    # import dates
    signature_date = as.Date(signature_date, format = "%d/%m/%Y"),
    call_deadline_date = as.Date(call_deadline_date, format = "%d/%m/%Y"),
    signature_year = str_sub(signature_date, 1, 4),
    call_year = str_sub(call_deadline_date, 1, 4),
    start_year = str_sub(start_date, 1, 4),
    signature_year = int(signature_year),
    call_year = int(call_year),
    start_year = int(start_year)
  ) %>%
  left_join(country_codes, by = "country_code") %>%
  filter(!is.na(start_date))
```

Last, we write the view by year to the `./data` folder

```{r write, include=FALSE}
# store data types
df_schema <- df_raw %>%
  map_chr(class)

# split CSVs by year
df_years <-
  df_raw %>%
  distinct(start_year) %>%
  pull() %>%
  sort()
df_raw <- df_raw %>%
  arrange(start_year) %>%
  group_by(start_year) %>%
  group_split() %>%
  setNames(df_years)

# write to ./data
file_names <- here("data", glue("cordis-plus-{df_years}.csv"))
walk2(df_raw, file_names, vroom_write, delim = ",")
write_yaml(df_schema, here("data", "schema-cordis-plus.yml"))
```

